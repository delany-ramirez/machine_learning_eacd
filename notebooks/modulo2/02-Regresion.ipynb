{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5l-HWPKFLU1"
   },
   "source": [
    "# Implementación de Regresión Lineal con Descenso del Gradiente\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "- Implementar una regresión lineal simple utilizando Python y aplicar el descenso del gradiente para optimizar el modelo.\n",
    "\n",
    "**Dataset Propuesto:**\n",
    "\n",
    "- Utilizar el conjunto de datos 'California Housing Dataset' disponible en Scikit-learn.\n",
    "\n",
    "**Tareas:**\n",
    "- Cargar y explorar el dataset.\n",
    "- Implementar la regresión lineal utilizando Scikit-learn.\n",
    "- Implementar manualmente el descenso del gradiente.\n",
    "- Comparar los resultados y analizar el rendimiento.\n",
    "\n",
    "## Paso 1 - Carga y Exploración del Dataset\n",
    "Contenido:\n",
    "\n",
    "**Cargar el Dataset:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2597,
     "status": "ok",
     "timestamp": 1729944214612,
     "user": {
      "displayName": "Delany Ramirez Del Río",
      "userId": "00157053603326049407"
     },
     "user_tz": 300
    },
    "id": "XoZ8I0z0Fh9Q"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "california = fetch_california_housing()\n",
    "X = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "y = pd.Series(california.target, name='MedHouseVal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q-d2l3PLuMe"
   },
   "source": [
    "Imprimir el target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28RdhbTgLwgN",
    "outputId": "d46c754a-8de0-4891-f917-d24a18f7fda4"
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnAMf1zWLwtk"
   },
   "source": [
    "Imprimir los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "An9JN-nNLyQU",
    "outputId": "f5883d27-755c-4d20-c386-0396aae29a7a"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYP0Tmj9Flc_"
   },
   "source": [
    "**Exploración Inicial:**\n",
    "- Visualizar las primeras filas del DataFrame.\n",
    "- Describir las variables y su significado.\n",
    "- Realizar gráficos exploratorios (scatter plots, histogramas).\n",
    "\n",
    "## Paso 2 - Regresión Lineal con Scikit-learn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puDGWCSGFw92",
    "outputId": "922e5fba-5274-44ce-ed7a-2ecaa0e0a262"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['MedInc']], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el Modelo:\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Extraer b0 (intercepto) and b1 (pendiente)\n",
    "b0 = modelo.intercept_\n",
    "b1 = modelo.coef_[0]\n",
    "\n",
    "print(f\"Intercept (b0): {b0}\")\n",
    "print(f\"Coefficient (b1): {b1}\")\n",
    "\n",
    "# Evaluar el Modelo:\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R^2: {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WyXVPQRF738"
   },
   "source": [
    "## Paso 3 - Implementación Manual del Descenso del Gradiente\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lrrx03ZFGAXj",
    "outputId": "5f861931-b1e1-460c-b3d8-4524bb91442b"
   },
   "outputs": [],
   "source": [
    "# Inicializar Parámetros:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_b = np.c_[np.ones((X_train.shape[0], 1)), X_train.values]  # Agregar término de sesgo\n",
    "theta = np.random.randn(2, 1)  # Inicializar theta aleatoriamente\n",
    "\n",
    "\n",
    "\n",
    "# Definir Hiperparámetros:\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iter = 1000\n",
    "\n",
    "# Algoritmo de Descenso del Gradiente:\n",
    "\n",
    "m = X_b.shape[0]\n",
    "\n",
    "for iteration in range(n_iter):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y_train.values.reshape(-1, 1))\n",
    "    theta = theta - learning_rate * gradients\n",
    "\n",
    "print(f\"Intercepto (b0): {theta[0]}\")\n",
    "print(f\"Coefficiente (b1): {theta[1]}\")\n",
    "\n",
    "# Predicciones y Evaluación:\n",
    "\n",
    "X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test.values]\n",
    "y_pred_manual = X_test_b.dot(theta)\n",
    "\n",
    "mse_manual = mean_squared_error(y_test, y_pred_manual)\n",
    "r2_manual = r2_score(y_test, y_pred_manual)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"MSE (Descenso del Gradiente): {mse_manual:.2f}\")\n",
    "print(f\"R^2 (Descenso del Gradiente): {r2_manual:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd395iYxKA5R",
    "outputId": "34e00349-b3d0-4561-8310-51c2f5f54332"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inicializar Parámetros:\n",
    "\n",
    "X_b = np.c_[np.ones((X_train.shape[0], 1)), X_train.values]  # Agregar término de sesgo\n",
    "theta = np.random.randn(2, 1)  # Inicializar theta aleatoriamente\n",
    "\n",
    "print(theta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RI14jASytPKS",
    "outputId": "cffe1279-50ca-4820-b278-a77cdc6f8d91"
   },
   "outputs": [],
   "source": [
    "# Definir Hiperparámetros:\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_iter = 1000\n",
    "\n",
    "# Algoritmo de Descenso del Gradiente:\n",
    "\n",
    "m = X_b.shape[0]\n",
    "\n",
    "cost_history = []  # Lista para almacenar el costo en cada iteración\n",
    "theta_history = []  # Lista para almacenar los valores de theta en cada iteración\n",
    "\n",
    "for iteration in range(n_iter):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y_train.values.reshape(-1, 1))\n",
    "\n",
    "    theta = theta - learning_rate * gradients\n",
    "    theta_history.append(theta.copy())\n",
    "    # Calcular el costo actual y almacenarlo\n",
    "    cost = (1/m) * np.sum((X_b.dot(theta) - y_train.values.reshape(-1, 1))**2)\n",
    "    cost_history.append(cost)\n",
    "\n",
    "print(f\"Intercepto (b0): {theta[0]}\")\n",
    "print(f\"Coefficiente (b1): {theta[1]}\")\n",
    "\n",
    "# Predicciones y Evaluación:\n",
    "\n",
    "X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test.values]\n",
    "y_pred_manual = X_test_b.dot(theta)\n",
    "\n",
    "mse_manual = mean_squared_error(y_test, y_pred_manual)\n",
    "r2_manual = r2_score(y_test, y_pred_manual)\n",
    "\n",
    "\n",
    "print(f\"MSE (Descenso del Gradiente): {mse_manual:.2f}\")\n",
    "print(f\"R^2 (Descenso del Gradiente): {r2_manual:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2s8BLShKCR_",
    "outputId": "d0b22ebb-864c-4a0d-fab1-11521bd56dbd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar la figura y los subgráficos\n",
    "# Añadir un tercer subgráfico para los parámetros theta\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Gráfico del costo vs. iteraciones\n",
    "axes[0].plot(range(n_iter), cost_history, color='blue')\n",
    "axes[0].set_xlabel('Número de Iteraciones')\n",
    "axes[0].set_ylabel('Costo')\n",
    "axes[0].set_title('Recorrido del Gradiente (Costo vs. Iteraciones)')\n",
    "\n",
    "# Gráfico de los parámetros theta\n",
    "theta_0_history = [theta[0][0] for theta in theta_history]\n",
    "theta_1_history = [theta[1][0] for theta in theta_history]\n",
    "\n",
    "axes[1].plot(range(n_iter), theta_0_history, label='theta_0 (Intercepto)')\n",
    "axes[1].plot(range(n_iter), theta_1_history, label='theta_1 (Coeficiente)')\n",
    "axes[1].set_xlabel('Número de Iteraciones')\n",
    "axes[1].set_ylabel('Valor de Theta')\n",
    "axes[1].set_title('Evolución de los Parámetros Theta')\n",
    "axes[1].legend()\n",
    "\n",
    "# Gráfico de los datos y la línea de regresión\n",
    "axes[2].scatter(X_test.values, y_test.values, color='blue', label='Datos Reales')\n",
    "axes[2].plot(X_test.values, y_pred_manual, color='red', linewidth=2, label='Línea de Regresión')\n",
    "axes[2].set_xlabel('Ingresos medios en el grupo de bloques (MedInc)')\n",
    "axes[2].set_ylabel('Valor Medio de la Vivienda (MedHouseVal)')\n",
    "axes[2].set_title('Regresión Lineal Ajustada')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUZhoDfpGLOx"
   },
   "source": [
    "## Paso 4 - Comparación y Análisis de Resultados\n",
    "\n",
    "**Comparar Métricas:**\n",
    "\n",
    "- ¿Los resultados son similares?\n",
    "- ¿Qué diferencias observas y a qué pueden deberse?\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
