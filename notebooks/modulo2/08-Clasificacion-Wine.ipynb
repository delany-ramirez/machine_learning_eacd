{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a7de12",
   "metadata": {},
   "source": [
    "\n",
    "# Sesión 08 — Clasificación con *Wine Dataset* (scikit-learn)\n",
    "\n",
    "Este cuaderno reproduce un flujo típico de clasificación con **Python 3.x** usando el conjunto de datos **Wine**.  \n",
    "Incluye: carga de datos, exploración, separación *train/test*, estandarización, ajuste de varios clasificadores, evaluación con métricas clásicas y curvas ROC (one-vs-rest).\n",
    "\n",
    "> Requisitos: `pandas`, `numpy`, `scikit-learn`, `matplotlib`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Importaciones básicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, classification_report,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Configuración de impresión\n",
    "pd.set_option('display.precision', 3)\n",
    "np.set_printoptions(precision=3, suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc1f46",
   "metadata": {},
   "source": [
    "## 1) Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "wine = load_wine(as_frame=True)\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "feature_names = X.columns.tolist()\n",
    "target_names = wine.target_names\n",
    "\n",
    "print(\"Dimensiones X:\", X.shape)\n",
    "print(\"Clases:\", target_names)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36dcff5",
   "metadata": {},
   "source": [
    "## 2) Exploración rápida de datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "X.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d23e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Histogramas simples de algunas variables (sin seaborn)\n",
    "cols = feature_names[:6]  # primeras 6 para no sobrecargar\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 7))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(cols):\n",
    "    axes[i].hist(X[col], bins=20)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"Frecuencia\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2b25f",
   "metadata": {},
   "source": [
    "## 3) Partición *train/test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43064dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e714438",
   "metadata": {},
   "source": [
    "## 4) Entrenamiento y evaluación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Función auxiliar para entrenar y evaluar\n",
    "def evaluar_modelo(nombre, pipe, X_train, X_test, y_train, y_test):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average='macro', zero_division=0\n",
    "    )\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n=== {nombre} ===\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Precision (macro): {prec:.3f} | Recall (macro): {rec:.3f} | F1 (macro): {f1:.3f}\")\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "    disp.plot(xticks_rotation=45)\n",
    "    plt.title(f\"Matriz de confusión — {nombre}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return {\"name\": nombre, \"pipeline\": pipe, \"y_pred\": y_pred, \"acc\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07896ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=500, multi_class=\"auto\"))\n",
    "])\n",
    "res_logreg = evaluar_modelo(\"Logistic Regression\", logreg, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "tree = DecisionTreeClassifier(random_state=42, max_depth=None)\n",
    "res_tree = evaluar_modelo(\"Decision Tree\", tree, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ffaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=300, max_depth=None)\n",
    "res_rf = evaluar_modelo(\"Random Forest\", rf, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01df2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "svm_rbf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "])\n",
    "res_svm = evaluar_modelo(\"SVM (RBF)\", svm_rbf, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9f010",
   "metadata": {},
   "source": [
    "### 4.1) Validación cruzada (accuracy, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for nombre, pipe in [\n",
    "    (\"LogReg\", logreg),\n",
    "    (\"DecisionTree\", tree),\n",
    "    (\"RandomForest\", rf),\n",
    "    (\"SVM-RBF\", svm_rbf),\n",
    "]:\n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    print(f\"{nombre}: mean={scores.mean():.3f} ± {scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04131757",
   "metadata": {},
   "source": [
    "## 5) Curvas ROC (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def plot_roc_ovr(nombre, estimator, X_train, X_test, y_train, y_test):\n",
    "    n_classes = len(np.unique(y))\n",
    "    y_train_bin = label_binarize(y_train, classes=np.arange(n_classes))\n",
    "    y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "    clf = OneVsRestClassifier(estimator)\n",
    "    clf.fit(X_train, y_train_bin)\n",
    "\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        y_score = clf.predict_proba(X_test)\n",
    "    else:\n",
    "        scores = clf.decision_function(X_test)\n",
    "        if scores.ndim == 1:\n",
    "            scores = scores[:, None]\n",
    "        minv = scores.min(axis=0, keepdims=True)\n",
    "        maxv = scores.max(axis=0, keepdims=True)\n",
    "        y_score = (scores - minv) / (maxv - minv + 1e-12)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"Clase {target_names[i]} (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(f\"ROC One-vs-Rest — {nombre}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_ovr(\"Logistic Regression\", LogisticRegression(max_iter=500), X_train, X_test, y_train, y_test)\n",
    "plot_roc_ovr(\"SVM (RBF)\", SVC(kernel=\"rbf\", probability=True, random_state=42), X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95f169",
   "metadata": {},
   "source": [
    "## 6) Importancia de variables (árboles/bosques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d33ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "rf_fit = RandomForestClassifier(random_state=42, n_estimators=300)\n",
    "rf_fit.fit(X_train, y_train)\n",
    "\n",
    "importances = rf_fit.feature_importances_\n",
    "idx = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Top 10 variables por importancia:\")\n",
    "for i in idx[:10]:\n",
    "    print(f\"{feature_names[i]:30s} {importances[i]:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "top_k = 10\n",
    "plt.bar(range(top_k), importances[idx][:top_k])\n",
    "plt.xticks(range(top_k), [feature_names[i] for i in idx[:top_k]], rotation=45, ha='right')\n",
    "plt.ylabel(\"Importancia (Gini)\")\n",
    "plt.title(\"Importancia de variables — Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac47a0",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Conclusiones rápidas\n",
    "- El conjunto **Wine** es de **3 clases** y **13 atributos**; responde bien a clasificadores lineales con *scaling* y a métodos no lineales.\n",
    "- Revise *accuracy*, *macro-F1* y matrices de confusión para comparar modelos.\n",
    "- Use validación cruzada para estimar rendimiento fuera de muestra.\n",
    "\n",
    "> Lecturas sugeridas: (Han & Kamber, 2012), (Hastie, Tibshirani & Friedman, 2009).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
