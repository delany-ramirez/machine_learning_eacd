{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c01709",
   "metadata": {},
   "source": [
    "\n",
    "# Sesión 08 — Clasificación con **Wine Quality (UCI)**\n",
    "\n",
    "Este cuaderno implementa un flujo clásico de **clasificación** en Python usando el dataset **Wine Quality** de UCI (red + white).  \n",
    "Incluye: carga de datos, EDA, preparación, división *train/test*, estandarización, ajuste de modelos (LogReg, Árbol, Random Forest, SVM), validación cruzada, métricas, matriz de confusión, **ROC** y **importancia de variables**.\n",
    "\n",
    "> Requisitos: `pandas`, `numpy`, `scikit-learn`, `matplotlib`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51602962",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Descarga de datos (instrucciones)\n",
    "\n",
    "Este notebook espera dos archivos en el mismo directorio o ruta accesible:\n",
    "\n",
    "- `winequality-red.csv`\n",
    "- `winequality-white.csv`\n",
    "\n",
    "**Fuentes UCI** (copiar/pegar en el navegador):\n",
    "- Red: https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
    "- White: https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n",
    "\n",
    "Colócalos en `./` o ajusta las rutas en la celda de carga. Si ya los tienes en esta sesión, ponlos en `/mnt/data/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6b4f1",
   "metadata": {},
   "source": [
    "## 1) Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, classification_report,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pd.set_option('display.precision', 3)\n",
    "np.set_printoptions(precision=3, suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608897ea",
   "metadata": {},
   "source": [
    "## 2) Carga y unión de datos (red + white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f310239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rutas locales (ajustar si es necesario)\n",
    "path_red = Path('data/winequality-red.csv')\n",
    "path_white = Path('data/winequality-white.csv')\n",
    "\n",
    "if not path_red.exists() or not path_white.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"No se encontraron los CSVs de UCI. \"\n",
    "        \"Descarga 'winequality-red.csv' y 'winequality-white.csv' de UCI y colócalos en la raiz del proyecto.\"\n",
    "    )\n",
    "\n",
    "# Los archivos de UCI usan ';' como separador\n",
    "red = pd.read_csv(path_red, sep=';')\n",
    "white = pd.read_csv(path_white, sep=';')\n",
    "\n",
    "red['type'] = 'red'\n",
    "white['type'] = 'white'\n",
    "\n",
    "df = pd.concat([red], axis=0, ignore_index=True)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b8793",
   "metadata": {},
   "source": [
    "## 3) Limpieza y creación de la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comprobación de nulos\n",
    "print(\"Nulos por columna:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# En este dataset no suele haber nulos; si hubiera, podemos imputar simple:\n",
    "# df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Variable objetivo: umbral de calidad (clasificación binaria)\n",
    "# Opción didáctica equilibrada: >= 6 como 'buena' (1), < 6 'no-buena' (0)\n",
    "df['quality_label'] = (df['quality'] >= 6).astype(int)\n",
    "\n",
    "# Separar X/y\n",
    "features = [c for c in df.columns if c not in ['quality', 'quality_label']]\n",
    "X = df[features].copy()\n",
    "y = df['quality_label'].copy()\n",
    "\n",
    "# One-hot para 'type' (red/white)\n",
    "X = pd.get_dummies(X, columns=['type'], drop_first=True)\n",
    "\n",
    "print(\"Dimensiones X:\", X.shape, \"| y:\", y.shape)\n",
    "print(\"Distribución de y:\")\n",
    "print(y.value_counts(normalize=True).rename('proportion'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a8236f",
   "metadata": {},
   "source": [
    "## 4) EDA rápida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fbc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histograma de la calidad original\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df['quality'], bins=10)\n",
    "plt.title(\"Distribución de 'quality' (0-10)\")\n",
    "plt.xlabel(\"quality\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b41cd",
   "metadata": {},
   "source": [
    "## 5) Partición *train/test* (estratificada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265399d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e7921",
   "metadata": {},
   "source": [
    "## 6) Entrenamiento y evaluación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para evaluar modelos\n",
    "def evaluar_modelo(nombre, pipe, X_train, X_test, y_train, y_test, target_names=('No-buena','Buena')):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average='binary', zero_division=0\n",
    "    )\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n=== {nombre} ===\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Precision: {prec:.3f} | Recall: {rec:.3f} | F1: {f1:.3f}\")\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names).plot()\n",
    "    plt.title(f\"Matriz de confusión — {nombre}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return {\"name\": nombre, \"pipeline\": pipe, \"y_pred\": y_pred, \"acc\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modelo 1: Regresión Logística\n",
    "logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "res_logreg = evaluar_modelo(\"Logistic Regression\", logreg, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd2144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "res_knn = evaluar_modelo(\"K-Nearest Neighbors\", knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c09c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: Decision Tree\n",
    "tree = DecisionTreeClassifier(random_state=42, max_depth=None)\n",
    "res_tree = evaluar_modelo(\"Decision Tree\", tree, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ab723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 3: Random Forest\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=400, max_depth=None)\n",
    "res_rf = evaluar_modelo(\"Random Forest\", rf, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 4: SVM (RBF)\n",
    "svm_rbf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "])\n",
    "res_svm = evaluar_modelo(\"SVM (RBF)\", svm_rbf, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a31981f",
   "metadata": {},
   "source": [
    "### 6.1) Validación cruzada (k=5, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Validación cruzada estratificada (5 folds)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for nombre, pipe in [\n",
    "    (\"LogReg\", logreg),\n",
    "    (\"DecisionTree\", tree),\n",
    "    (\"RandomForest\", rf),\n",
    "    (\"SVM-RBF\", svm_rbf),\n",
    "]:\n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    print(f\"{nombre}: mean={scores.mean():.3f} ± {scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a97462d",
   "metadata": {},
   "source": [
    "## 7) Curva ROC (binaria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c352de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Curvas ROC para modelos con probabilidad\n",
    "def plot_roc_bin(nombre, fitted_pipe, X_test, y_test):\n",
    "    # Si el estimador soporta predict_proba usarlo; si no, decision_function\n",
    "    if hasattr(fitted_pipe, \"predict_proba\"):\n",
    "        y_score = fitted_pipe.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        # decision_function puede ser usado como score\n",
    "        if hasattr(fitted_pipe, \"decision_function\"):\n",
    "            y_score = fitted_pipe.decision_function(X_test)\n",
    "            # Normalización min-max por si la escala es arbitraria\n",
    "            y_score = (y_score - y_score.min()) / (y_score.max() - y_score.min() + 1e-12)\n",
    "        else:\n",
    "            raise AttributeError(\"El estimador no provee predict_proba ni decision_function.\")\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1], linestyle='--')\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(f\"ROC — {nombre}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ajustar y graficar para LogReg y SVM\n",
    "logreg.fit(X_train, y_train)\n",
    "plot_roc_bin(\"Logistic Regression\", logreg, X_test, y_test)\n",
    "\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "plot_roc_bin(\"SVM (RBF)\", svm_rbf, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed817d",
   "metadata": {},
   "source": [
    "## 8) Importancia de variables (árboles/bosques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importancia de variables con Random Forest\n",
    "rf_fit = RandomForestClassifier(random_state=42, n_estimators=400)\n",
    "rf_fit.fit(X_train, y_train)\n",
    "importances = rf_fit.feature_importances_\n",
    "idx = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Top 12 variables por importancia:\")\n",
    "for i in idx[:12]:\n",
    "    print(f\"{X.columns[i]:30s} {importances[i]:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "top_k = len(X.columns)\n",
    "plt.bar(range(top_k), importances[idx][:top_k])\n",
    "plt.xticks(range(top_k), [X.columns[i] for i in idx[:top_k]], rotation=45, ha='right')\n",
    "plt.ylabel(\"Importancia (Gini)\")\n",
    "plt.title(\"Importancia de variables — Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c1fe9",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Notas didácticas\n",
    "- Umbral de calidad: puedes cambiarlo a `>= 7` para un problema más **desbalanceado** (alta precisión, menor recall).  \n",
    "- Escalado: necesario para modelos sensibles a la escala (LogReg, SVM).  \n",
    "- Considera comparar *accuracy* con *AUC-ROC* y *F1* cuando las clases estén desbalanceadas.  \n",
    "- Para tareas multi-clase, puedes predecir la calidad exacta (0–10), pero muchas celdas deben adaptarse.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
