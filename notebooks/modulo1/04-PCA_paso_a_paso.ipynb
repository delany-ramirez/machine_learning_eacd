{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10fced7",
   "metadata": {},
   "source": [
    "\n",
    "# PCA paso a paso con Python (inspirado en StatQuest)\n",
    "\n",
    "> Este notebook reproduce el ejemplo clásico de **PCA** explicado paso a paso,\n",
    "incluyendo: centrado/estandarización, matriz de covarianza, **autovectores** / **autovalores**, **SVD**, **scores** (proyecciones), **varianza explicada**, **biplot**, reconstrucción y comparación con `scikit-learn`.\n",
    "\n",
    "**Autor:** DataMining TA‑GPT · **Fecha:** 2025-09-02\n",
    "\n",
    "**Requisitos:** `numpy`, `pandas`, `matplotlib`, `scikit-learn` (opcional `plotly`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a05643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Importaciones y dataset sintético (2 genes × 6 muestras)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos simples (similar a \"mice vs genes\"): 6 muestras, 2 variables\n",
    "# Cada fila es una muestra (M1..M6), columnas son \"Gene1\" y \"Gene2\"\n",
    "X = np.array([\n",
    "    [2.5, 2.4],\n",
    "    [0.5, 0.7],\n",
    "    [2.2, 2.9],\n",
    "    [1.9, 2.2],\n",
    "    [3.1, 3.0],\n",
    "    [2.3, 2.7]\n",
    "], dtype=float)\n",
    "\n",
    "samples = [f\"M{i}\" for i in range(1, 7)]\n",
    "df = pd.DataFrame(X, index=samples, columns=[\"Gene1\", \"Gene2\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### Dispersión original\n",
    "plt.figure()\n",
    "plt.scatter(df[\"Gene1\"], df[\"Gene2\"])\n",
    "for i, s in enumerate(samples):\n",
    "    plt.annotate(s, (df.iloc[i,0], df.iloc[i,1]), xytext=(5,5), textcoords=\"offset points\")\n",
    "plt.xlabel(\"Gene1\")\n",
    "plt.ylabel(\"Gene2\")\n",
    "plt.title(\"Datos originales (sin centrar)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8cff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Centrado y estandarización (opcional)\n",
    "# Centrar: restar la media de cada columna\n",
    "mu = df.mean(axis=0).values\n",
    "X_centered = df.values - mu\n",
    "\n",
    "# Estandarizar (z-score) — útil cuando las escalas difieren\n",
    "sigma = df.std(axis=0, ddof=1).values\n",
    "X_std = (df.values - mu) / sigma\n",
    "\n",
    "pd.DataFrame(X_centered, index=samples, columns=df.columns).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0917926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualizar datos centrados\n",
    "plt.figure()\n",
    "plt.scatter(X_centered[:,0], X_centered[:,1])\n",
    "for i, s in enumerate(samples):\n",
    "    plt.annotate(s, (X_centered[i,0], X_centered[i,1]), xytext=(5,5), textcoords=\"offset points\")\n",
    "plt.axhline(0, linestyle=\"--\"); plt.axvline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Gene1 (centrado)\")\n",
    "plt.ylabel(\"Gene2 (centrado)\")\n",
    "plt.title(\"Datos centrados en el origen\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83516f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Matriz de covarianza y autodescomposición (eigen)\n",
    "# Usamos los datos centrados (recomendado para PCA clásico).\n",
    "C = np.cov(X_centered, rowvar=False)  # 2x2\n",
    "eigvals, eigvecs = np.linalg.eigh(C)  # eigh para matrices simétricas\n",
    "\n",
    "# Ordenar por varianza (descendente)\n",
    "idx = np.argsort(eigvals)[::-1]\n",
    "eigvals = eigvals[idx]\n",
    "eigvecs = eigvecs[:, idx]\n",
    "\n",
    "print(\"Covarianza:\\n\", C)\n",
    "print(\"\\nAutovalores (varianza por PC):\", eigvals)\n",
    "print(\"\\nAutovectores (columnas = PCs):\\n\", eigvecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec7117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Proyección a PCs (scores) y varianza explicada\n",
    "# Scores: proyección de los datos centrados sobre los autovectores\n",
    "scores = X_centered @ eigvecs   # 6x2\n",
    "explained_var = eigvals\n",
    "explained_ratio = eigvals / eigvals.sum()\n",
    "\n",
    "print(\"Scores (PC1, PC2):\\n\", np.round(scores, 3))\n",
    "print(\"\\nVarianza explicada:\", np.round(explained_ratio, 3))\n",
    "\n",
    "# Bar Scree plot\n",
    "plt.figure()\n",
    "plt.bar([1,2], explained_ratio, color=\"skyblue\")\n",
    "plt.xticks([1,2])\n",
    "plt.ylabel(\"Proporción de varianza explicada\")\n",
    "plt.xlabel(\"Componente principal\")\n",
    "plt.title(\"Bar Scree plot (2D)\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "# Proyección en PC1-PC2\n",
    "plt.figure()\n",
    "plt.scatter(scores[:,0], scores[:,1])\n",
    "for i, s in enumerate(samples):\n",
    "    plt.annotate(s, (scores[i,0], scores[i,1]), xytext=(5,5), textcoords=\"offset points\")\n",
    "plt.axhline(0, linestyle=\"--\"); plt.axvline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Muestras en el espacio de PCs (scores)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Biplot (scores + loadings)\n",
    "loadings = eigvecs * np.sqrt(eigvals)  # escala típica para biplot\n",
    "plt.figure()\n",
    "plt.scatter(scores[:,0], scores[:,1], label=\"Muestras\")\n",
    "for i, s in enumerate(samples):\n",
    "    plt.annotate(s, (scores[i,0], scores[i,1]), xytext=(5,5), textcoords=\"offset points\")\n",
    "\n",
    "# Vectores de variables (loadings)\n",
    "for j, col in enumerate(df.columns):\n",
    "    plt.arrow(0, 0, loadings[j,0], loadings[j,1], head_width=0.05, length_includes_head=True)\n",
    "    plt.text(loadings[j,0]*1.1, loadings[j,1]*1.1, col)\n",
    "\n",
    "plt.axhline(0, linestyle=\"--\"); plt.axvline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Biplot (PC scores y loadings)\")\n",
    "plt.legend()\n",
    "# plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e001b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Reconstrucción desde k PCs\n",
    "def reconstruct(scores, eigvecs, mu, k):\n",
    "    # Usa solo las primeras k columnas (PCs)\n",
    "    Vk = eigvecs[:, :k]\n",
    "    Sk = scores[:, :k]\n",
    "    X_rec = Sk @ Vk.T + mu  # Deshacer la proyección y sumar medias\n",
    "    return X_rec\n",
    "\n",
    "X_rec_1pc = reconstruct(scores, eigvecs, mu, k=1)\n",
    "X_rec_2pc = reconstruct(scores, eigvecs, mu, k=2)\n",
    "\n",
    "print(\"Reconstrucción con 1 PC:\\n\", np.round(X_rec_1pc, 3))\n",
    "print(\"\\nReconstrucción con 2 PCs (≈ original):\\n\", np.round(X_rec_2pc, 3))\n",
    "\n",
    "# Comparar visualmente 1PC vs original\n",
    "plt.figure()\n",
    "plt.scatter(df[\"Gene1\"], df[\"Gene2\"], label=\"Original\")\n",
    "plt.scatter(X_rec_1pc[:,0], X_rec_1pc[:,1], marker=\"x\", label=\"Reconstruido (1 PC)\")\n",
    "plt.xlabel(\"Gene1\"); plt.ylabel(\"Gene2\")\n",
    "plt.title(\"Original vs Reconstrucción con 1 PC\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 7. SVD y su relación con PCA\n",
    "# Para datos centrados: X_centered = U S V^T\n",
    "U, S, Vt = np.linalg.svd(X_centered, full_matrices=False)\n",
    "V = Vt.T\n",
    "# En PCA, autovectores de la covarianza (eigvecs) coinciden con V\n",
    "# y autovalores = (S^2)/(n-1)\n",
    "eigvals_svd = (S**2) / (X_centered.shape[0]-1)\n",
    "print(\"Autov. por SVD:\", np.round(eigvals_svd, 6))\n",
    "print(\"¿Coincide con eigen?:\", np.allclose(eigvals_svd, eigvals))\n",
    "print(\"¿Espacios V ~ eigvecs?:\", np.allclose(np.abs(V), np.abs(eigvecs), atol=1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c51765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Comparación con `scikit-learn`\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)  # por defecto centra los datos\n",
    "scores_skl = pca.fit_transform(df.values)\n",
    "print(\"Explained variance ratio (sklearn):\", np.round(pca.explained_variance_ratio_, 3))\n",
    "print(\"Componentes (filas=PCs):\\n\", np.round(pca.components_, 6))\n",
    "\n",
    "# Ajustes de signos pueden variar (PCs son únicos salvo signo)\n",
    "sign_fix = np.sign(pca.components_[0,0])\n",
    "components_skl = pca.components_.T * sign_fix\n",
    "scores_skl_adj = scores_skl * sign_fix\n",
    "\n",
    "print(\"\\n¿Componentes ~ eigvecs?:\", np.allclose(np.abs(components_skl), np.abs(eigvecs), atol=1e-6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9b6d6",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Consejos prácticos\n",
    "- **Estandariza** si las variables están en escalas distintas.\n",
    "- **Interpreta loadings** (dirección y contribución de variables) y **scores** (posición de muestras).\n",
    "- El número de PCs puede guiarse por **scree plot**, ≥80% de varianza, o validación externa.\n",
    "- PCA es lineal: patrones **no lineales** pueden requerir métodos como **t-SNE** o **UMAP**.\n",
    "- Evita mezclar **variables categóricas crudas**; codifícalas (one-hot) o usa técnicas afines (MCA).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388716c6",
   "metadata": {},
   "source": [
    "\n",
    "## Referencias sugeridas\n",
    "- Shlens, J. (2014). *A Tutorial on Principal Component Analysis* (arXiv:1404.1100).\n",
    "- Hastie, Tibshirani & Friedman (2009). *The Elements of Statistical Learning*, cap. 14.\n",
    "- StatQuest: **Principal Component Analysis (PCA), Step-by-Step** (video).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
